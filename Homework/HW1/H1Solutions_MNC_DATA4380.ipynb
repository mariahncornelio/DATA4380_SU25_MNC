{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6294a25a",
   "metadata": {},
   "source": [
    "# **DATA 4380 HW 1: Command Shell**\n",
    "## Mariah N Cornelio, 1002053287 \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c91499f",
   "metadata": {},
   "source": [
    "### **Exercise 1.**\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1a86481b",
   "metadata": {},
   "source": [
    "**pwd outputs /Users/marielle/Desktop/KaggleDatasets**\n",
    "- mkdir zip_files\n",
    "- mv *.zip /Users/marielle/Desktop/KaggleDatasets/zip_files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37bf15a3",
   "metadata": {},
   "source": [
    "### **Exercise 2.**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b2f17b62",
   "metadata": {},
   "source": [
    "- head -n 1 diabetes_prediction_dataset.csv\n",
    "    - This shows the variables gender, age, hypertension, etc. \n",
    "- head -n 1 diabetes_prediction_dataset.csv > diabetes_prediction_1.csv\n",
    "- head -n 1 diabetes_prediction_dataset.csv > diabetes_prediction_2.csv\n",
    "- head -n 1 diabetes_prediction_dataset.csv > diabetes_prediction_3.csv\n",
    "- wc diabetes_prediction_dataset.csv outputs 100001 lines, 142264 words, 3810356 characters\n",
    "    - The first line is the header so there are 10k entries, meaning each of the new .csv files should contain 33,333 entries\n",
    "- tail -n +2 diabetes_prediction_dataset.csv | head -n 33333 >> diabetes_prediction_1.csv\n",
    "    - Tail -n +2 skips the first line, head -n 33333 takes the next 33333 entries and the output of lines 2 to 333334 are directed to diabetes_prediction_1.csv\n",
    "- tail -n +33335 diabetes_prediction_dataset.csv | head -n 33333 >> diabetes_prediction_2.csv\n",
    "    - Tail -n +33335 skips the first 33334 rows, head -n 33333 grabs the next entries and the output of lines 33335 to 66667 are directed to diabetes_prediction_2.csv\n",
    "- tail -n +66668 diabetes_prediction_dataset.csv >> diabetes_prediction_3.csv\n",
    "    - This skips the first 66667 rows and takes the rest of the remaining data and outputs it into \n",
    "- Nano each file to check if it worked"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d23cd05",
   "metadata": {},
   "source": [
    "### **Exercise 3.**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "84d37139",
   "metadata": {},
   "source": [
    "- head -n 1 Heart_Disease_Prediction.csv\n",
    "    - Shows variables Age, Sex, Chest pain type, etc.\n",
    "    - The last column “Heart Disease” shows us the presence and absence variables that we are looking for for this exercise\n",
    "- head -n 1 Heart_Disease_Prediction.csv > Heart_Disease_Presence.csv\n",
    "- head -n 1 Heart_Disease_Prediction.csv > Heart_Disease_Absence.csv\n",
    "- grep \"Presence\" Heart_Disease_Prediction.csv >> Heart_Disease_Presence.csv\n",
    "    - We do not need to specify which column to grep from because every other column is a numerical value and the “Heart Disease” column is the only text variable column\n",
    "- grep \"Absence\" Heart_Disease_Prediction.csv >> Heart_Disease_Absence.csv\n",
    "- Nano each file to check if it worked"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "160581f6",
   "metadata": {},
   "source": [
    "### **Exercise 4.**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "005e9267",
   "metadata": {},
   "source": [
    "- head -2 car_web_scraped_dataset.csv\n",
    "- Take a look at what the data looks like and so we know which variables we need to use to find the fraction of cars that have no accidents\n",
    "- grep \"No accidents reported\" car_web_scraped_dataset.csv | wc -l\n",
    "    - 2223\n",
    "- tail -n +2 car_web_scraped_dataset.csv | wc -l\n",
    "    - 2840\n",
    "- echo \"scale=2; $(grep \"No accidents reported\" car_web_scraped_dataset.csv | wc -l) / $(tail -n +2 car_web_scraped_dataset.csv | wc -l)\" | bc\n",
    "    - Calculates the fraction of cars who have had no accidents by finding how many cars reported no accidents and dividing that by the number of entries in the dataset, excluding the first line\n",
    "    - Scale is the number of decimal places and bc means basic calculator \n",
    "    - 2223/2840\n",
    "- **The answer is: 0.78**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53a09efb",
   "metadata": {},
   "source": [
    "### **Exercise 5.**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d27eee41",
   "metadata": {},
   "source": [
    "- head -2 Housing.csv\n",
    "- sed -e 's/yes/1/g' -e 's/no/0/g' -e 's/unfurnished/0/g' -e 's/semi-furnished/2/g' -e 's/furnished/1/g' Housing.csv > Housing_modified.csv\n",
    "    - -e tells sed to execute an expression\n",
    "    - The expression goes “s for substitution / the word to be replaced / what to replace it with / global meaning for all instances” and then it pipes into the next expression to be executed\n",
    "    - Replaced “furnished” last because sed is case-sensitive and will find the word “furnished” no matter where it is placed within the word\n",
    "- nano Housing_modified.csv to check if it worked"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "136f2f58",
   "metadata": {},
   "source": [
    "### **Exercise 6.**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7209c563",
   "metadata": {},
   "source": [
    "- head -2 Mall_Customers.csv\n",
    "- cut -d ',' -f 2- Mall_Customers.csv > Mall_Customers_noCUSTOMERID.csv\n",
    "    - Cuts by the comma delimiter and gives fields starting from column 2 and so on (because the CustomerID column was column 1 in the original .csv)\n",
    "- nano Mall_Customers_noCUSTOMERID.csv to check if it worked"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24ef034f",
   "metadata": {},
   "source": [
    "### **Exercise 7.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa5776cb",
   "metadata": {},
   "source": [
    "**For this exercise, I had to do some data cleaning beforehand. This was because if I ran the pipeline on the original data, it output error  “Parse error: bad character '�' <stdin>:16”. I went to that line and found that the dataset uses an unrecognized character so in order to do so, we had to change that character so the computer would not read non-numeric values.**\n",
    "    \n",
    "- head -2 \"world all university rank and rank score.csv\"\n",
    "- sed 's/–/-/g' \"world all university rank and rank score.csv\" > cleaned_world_university.csv\n",
    "- tail -n +2 cleaned_world_university.csv | cut -d ',' -f 5-8 | tr ',' '+' | bc > university_rank_sums.csv\n",
    "    - Skips the first row with the headers of the file, only keeps fields 5-8 while cutting out the rest by the comma delimiter, translates the commas to +’s, and then puts that into the basic calculator where the output goes to the university_rank_sums.csv\n",
    "- nano university_rank_sums.csv to see if it worked\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "866bb340",
   "metadata": {},
   "source": [
    "### **Exercise 8.**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "df71ea51",
   "metadata": {},
   "source": [
    "- head -2 \"cancer patient data sets.csv\"\n",
    "- head -n 1 \"cancer patient data sets.csv\" > cancer_data_sorted.csv\n",
    "- tail -n +2 \"cancer patient data sets.csv\" | sort -t ',' -k3,3n >> cancer_data_sorted.csv\n",
    "    - Sorts by delimiter comma, and sorts by field/column 3 (which is Age), 3,3 sorts by Age only, and then n stands for numerical \n",
    "- nano cancer_data_sorted.csv"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
